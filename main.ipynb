{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrfL1rC6/+rIyA8xEUWiOm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "class StorageObject():\n",
        "\n",
        "    def __init__(self, path='/content/drive', filename='SaveDataObject.csv'):\n",
        "        self.path = path\n",
        "        self.filename = filename\n",
        "        self.fullpath = path + '/' + filename\n",
        "        # записывать в файл следует список (list) хранящий данные в следующем порядке:\n",
        "        #   1. seed - параметр, который установлен в функции torch.manual_seed(seed);\n",
        "        #   2. количество скрытых нейронных слоев\n",
        "        #   3. количество нейроннов в каждом скрытом слое\n",
        "        #   4. количество эпох (итераций обучения)\n",
        "        #   5. вид функции loss\n",
        "        #   6. метод оптимизации\n",
        "        #   7. learning rate\n",
        "        #   8. weight decay\n",
        "        #   9. loss на тренировочных данных\n",
        "        #  10. accuracy на тренировочных данных\n",
        "        #  11. loss на тестовых данных\n",
        "        #  12. accuracy на тестовых данных\n",
        "        #  13 - 112. маска тренировочных данных. 1, если позиция используется для обучения, 0, если используется для теста.\n",
        "\n",
        "        self.storage_headers = ['seed', 'hidden_layers_count', 'hidden_demention',\n",
        "                                  'epoch', 'loss_function', 'optimizer', 'learning_rate',\n",
        "                                  'weight_decay', 'train_loss_value', 'train_accuracy_value',\n",
        "                                  'test_loss_value', 'test_accuracy_value',\n",
        "                                  'l_01_c_01', 'l_01_c_02', 'l_01_c_03', 'l_01_c_04', 'l_01_c_05',\n",
        "                                  'l_01_c_06', 'l_01_c_07', 'l_01_c_08', 'l_01_c_09', 'l_01_c_10',\n",
        "                                  'l_02_c_01', 'l_02_c_02', 'l_02_c_03', 'l_02_c_04', 'l_02_c_05',\n",
        "                                  'l_02_c_06', 'l_02_c_07', 'l_02_c_08', 'l_02_c_09', 'l_02_c_10',\n",
        "                                  'l_03_c_01', 'l_03_c_02', 'l_03_c_03', 'l_03_c_04', 'l_03_c_05',\n",
        "                                  'l_03_c_06', 'l_03_c_07', 'l_03_c_08', 'l_03_c_09', 'l_03_c_10',\n",
        "                                  'l_04_c_01', 'l_04_c_02', 'l_04_c_03', 'l_04_c_04', 'l_04_c_05',\n",
        "                                  'l_04_c_06', 'l_04_c_07', 'l_04_c_08', 'l_04_c_09', 'l_04_c_10',\n",
        "                                  'l_05_c_01', 'l_05_c_02', 'l_05_c_03', 'l_05_c_04', 'l_05_c_05',\n",
        "                                  'l_05_c_06', 'l_05_c_07', 'l_05_c_08', 'l_05_c_09', 'l_05_c_10',\n",
        "                                  'l_06_c_01', 'l_06_c_02', 'l_06_c_03', 'l_06_c_04', 'l_06_c_05',\n",
        "                                  'l_06_c_06', 'l_06_c_07', 'l_06_c_08', 'l_06_c_09', 'l_06_c_10',\n",
        "                                  'l_07_c_01', 'l_07_c_02', 'l_07_c_03', 'l_07_c_04', 'l_07_c_05',\n",
        "                                  'l_07_c_06', 'l_07_c_07', 'l_07_c_08', 'l_07_c_09', 'l_07_c_10',\n",
        "                                  'l_08_c_01', 'l_08_c_02', 'l_08_c_03', 'l_08_c_04', 'l_08_c_05',\n",
        "                                  'l_08_c_06', 'l_08_c_07', 'l_08_c_08', 'l_08_c_09', 'l_08_c_10',\n",
        "                                  'l_09_c_01', 'l_09_c_02', 'l_09_c_03', 'l_09_c_04', 'l_09_c_05',\n",
        "                                  'l_09_c_06', 'l_09_c_07', 'l_09_c_08', 'l_09_c_09', 'l_09_c_10',\n",
        "                                  'l_10_c_01', 'l_10_c_02', 'l_10_c_03', 'l_10_c_04', 'l_10_c_05',\n",
        "                                  'l_10_c_06', 'l_10_c_07', 'l_10_c_08', 'l_10_c_09', 'l_10_c_10',\n",
        "                                ]\n",
        "    def connect(self):\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        # os.chdir(self.path)\n",
        "        # %cd self.path\n",
        "\n",
        "    def dataadd(self, adding_data_list):\n",
        "\n",
        "        save_line = ', '.join(str(x) for x in adding_data_list)+'\\n'\n",
        "        openmode = 'a'\n",
        "\n",
        "        if not os.path.exists(self.fullpath):\n",
        "            head_line = ', '.join(str(x) for x in self.storage_headers)+'\\n'\n",
        "            openmode = 'w'\n",
        "            save_line = head_line + save_line\n",
        "\n",
        "        try:\n",
        "            with open(self.fullpath, mode=openmode) as fp:\n",
        "                fp.write(save_line)\n",
        "        except OSError as err:\n",
        "            print(\"OS error:\", err)"
      ],
      "metadata": {
        "id": "D2e4PaPrpRkr"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_draft = [[1, 1],  [1, 2],  [1, 3],  [1, 4],  [1, 5],  [1, 6],  [1, 7],  [1, 8],  [1, 9],  [1, 10],\n",
        "           [2, 1],  [2, 2],  [2, 3],  [2, 4],  [2, 5],  [2, 6],  [2, 7],  [2, 8],  [2, 9],  [2, 10],\n",
        "           [3, 1],  [3, 2],  [3, 3],  [3, 4],  [3, 5],  [3, 6],  [3, 7],  [3, 8],  [3, 9],  [3, 10],\n",
        "           [4, 1],  [4, 2],  [4, 3],  [4, 4],  [4, 5],  [4, 6],  [4, 7],  [4, 8],  [4, 9],  [4, 10],\n",
        "           [5, 1],  [5, 2],  [5, 3],  [5, 4],  [5, 5],  [5, 6],  [5, 7],  [5, 8],  [5, 9],  [5, 10],\n",
        "           [6, 1],  [6, 2],  [6, 3],  [6, 4],  [6, 5],  [6, 6],  [6, 7],  [6, 8],  [6, 9],  [6, 10],\n",
        "           [7, 1],  [7, 2],  [7, 3],  [7, 4],  [7, 5],  [7, 6],  [7, 7],  [7, 8],  [7, 9],  [7, 10],\n",
        "           [8, 1],  [8, 2],  [8, 3],  [8, 4],  [8, 5],  [8, 6],  [8, 7],  [8, 8],  [8, 9],  [8, 10],\n",
        "           [9, 1],  [9, 2],  [9, 3],  [9, 4],  [9, 5],  [9, 6],  [9, 7],  [9, 8],  [9, 9],  [9, 10],\n",
        "           [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10]]\n",
        "\n",
        "y_draft =[[0.01], [0.02], [0.03], [0.04], [0.05], [0.06], [0.07], [0.08], [0.09], [0.1],\n",
        "          [0.02], [0.04], [0.06], [0.08], [0.1],  [0.12], [0.14], [0.16], [0.18], [0.2],\n",
        "          [0.03], [0.06], [0.09], [0.12], [0.15], [0.18], [0.21], [0.24], [0.27], [0.3],\n",
        "          [0.04], [0.08], [0.12], [0.16], [0.2],  [0.24], [0.28], [0.32], [0.36], [0.4],\n",
        "          [0.05], [0.1],  [0.15], [0.2],  [0.25], [0.3],  [0.35], [0.4],  [0.45], [0.5],\n",
        "          [0.06], [0.12], [0.18], [0.24], [0.3],  [0.36], [0.42], [0.48], [0.54], [0.6],\n",
        "          [0.07], [0.14], [0.21], [0.28], [0.35], [0.42], [0.49], [0.56], [0.63], [0.7],\n",
        "          [0.08], [0.16], [0.24], [0.32], [0.4],  [0.48], [0.56], [0.64], [0.72], [0.8],\n",
        "          [0.09], [0.18], [0.27], [0.36], [0.45], [0.54], [0.63], [0.72], [0.81], [0.9],\n",
        "          [0.1],  [0.2],  [0.3],  [0.4],  [0.5],  [0.6],  [0.7],  [0.8],  [0.9],  [1.0]]"
      ],
      "metadata": {
        "id": "shPRFIm26Jwo"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indexes_mask = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "                      0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "                      0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "                      0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "                      0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
        "                      0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
        "                      0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
        "                      0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
        "                      0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
        "                      0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ],
      "metadata": {
        "id": "Knnakl5FhrnE"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "ef52Ae95_CSo"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_demention, hidden_layers_count, hidden_demention, output_demention):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.layers = []\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "\n",
        "        self.layers.append(torch.nn.Linear(input_demention, hidden_demention))\n",
        "        self.layers[len(self.layers)-1].weight.data = torch.tensor(list(map(lambda x: list(map(lambda y: 0.5, range(input_demention))), range(hidden_demention))))\n",
        "\n",
        "        for cnt in range(hidden_layers_count):\n",
        "            self.layers.append(torch.nn.Linear(hidden_demention, hidden_demention))\n",
        "            self.layers[len(self.layers)-1].weight.data = torch.tensor(list(map(lambda x: list(map(lambda y: 0.5, range(hidden_demention))), range(hidden_demention))))\n",
        "\n",
        "        self.layers.append(torch.nn.Linear(hidden_demention, output_demention))\n",
        "        self.layers[len(self.layers)-1].weight.data = torch.tensor(list(map(lambda x: list(map(lambda y: 0.5, range(hidden_demention))), range(output_demention))))\n",
        "\n",
        "        # self.layer1 = torch.nn.Linear(input_demention, hidden_demention)\n",
        "        # self.layer1.weight.data = torch.tensor(list(map(lambda x: list(map(lambda y: 0.5, range(input_demention))), range(hidden_demention))))\n",
        "        # self.layer2 = torch.nn.Linear(hidden_demention, hidden_demention)\n",
        "        # self.layer2.weight.data = torch.tensor(list(map(lambda x: list(map(lambda y: 0.5, range(hidden_demention))), range(hidden_demention))))\n",
        "        # self.layer3 = torch.nn.Linear(hidden_demention, output_demention)\n",
        "        # self.layer3.weight.data = torch.tensor(list(map(lambda x: list(map(lambda y: 0.5, range(hidden_demention))), range(output_demention))))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        result = x\n",
        "\n",
        "        for layer in self.layers:\n",
        "            result = torch.nn.functional.relu(layer(result))\n",
        "\n",
        "        # x1 = torch.nn.functional.relu(self.layer1(x))\n",
        "        # x2 = torch.nn.functional.relu(self.layer2(x1))\n",
        "        # x3 = torch.nn.functional.relu(self.layer3(x2))\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "0NNJ11uoHb_v"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_weights(m):\n",
        "    # print(dir(m))\n",
        "    if 'weight' in dir(m):\n",
        "        print(m.weight)"
      ],
      "metadata": {
        "id": "Kq1yWDs_HfzR"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "\n",
        "    diff = torch.eq(torch.round(y_true*100), torch.round(y_pred*100))\n",
        "    result = torch.count_nonzero(diff)/len(y_true)*100\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "e7VjM9_4Ivny"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nn(model, optimizer, loss_fn, X_train, y_train, X_test, y_test, noe = 10):\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(noe), ncols=80, ascii=True, desc='Total'):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        y_pred = model(X_train)\n",
        "        loss = loss_fn(y_train, y_pred)\n",
        "        acc = accuracy(y_train, y_pred)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 10000 == 0:\n",
        "            y_pred = model(X_test)\n",
        "            test_loss = loss_fn(y_test, y_pred)\n",
        "            test_acc = accuracy(y_test, y_pred)\n",
        "\n",
        "            # print(f'Epoch: {epoch+1}, loss: {loss: .5f}, acc: {acc: .5f}%, test loss: {test_loss: .5f}, test acc: {test_acc: .5f}%')\n",
        "\n",
        "    model.eval()\n",
        "    y_pred = model(X_test)\n",
        "    test_loss = loss_fn(y_test, y_pred)\n",
        "    test_acc = accuracy(y_test, y_pred)\n",
        "\n",
        "    # print(f'Epoch: {epoch+1}, loss: {loss: .5f}, acc: {acc: .5f}%, test loss: {test_loss: .5f}, test acc: {test_acc: .5f}%')\n",
        "\n",
        "    return epoch+1, loss.item(), acc.item(), test_loss.item(), test_acc.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "lud2g4peHoKu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expres_storage = StorageObject(path='/content/drive/My Drive/Colab Notebooks/Python practice/Simple NN', filename='simple_nn_statistic.csv')\n",
        "expres_storage.connect()\n",
        "\n",
        "# записывать в файл следует список (list) хранящий данные в следующем порядке:\n",
        "#   1. seed - параметр, который установлен в функции torch.manual_seed(seed);\n",
        "#   2. количество скрытых нейронных слоев\n",
        "#   3. количество нейроннов в каждом скрытом слое\n",
        "#   4. количество эпох (итераций обучения)\n",
        "#   5. вид функции loss\n",
        "#   6. метод оптимизации\n",
        "#   7. learning rate\n",
        "#   8. weight decay\n",
        "#   9. loss на тренировочных данных\n",
        "#  10. accuracy на тренировочных данных\n",
        "#  11. loss на тестовых данных\n",
        "#  12. accuracy на тестовых данных\n",
        "#  13 - 112. маска тренировочных данных. 1, если позиция используется для обучения, 0, если используется для теста.\n",
        "\n",
        "expres_storage_headers = ['seed', 'hidden_layers_count', 'hidden_demention',\n",
        "                          'epoch', 'loss_function', 'optimizer', 'learning_rate',\n",
        "                          'weight_decay', 'train_loss_value', 'train_accuracy_value',\n",
        "                          'test_loss_value', 'test_accuracy_value',\n",
        "                          'l_01_c_01', 'l_01_c_02', 'l_01_c_03', 'l_01_c_04', 'l_01_c_05',\n",
        "                          'l_01_c_06', 'l_01_c_07', 'l_01_c_08', 'l_01_c_09', 'l_01_c_10',\n",
        "                          'l_02_c_01', 'l_02_c_02', 'l_02_c_03', 'l_02_c_04', 'l_02_c_05',\n",
        "                          'l_02_c_06', 'l_02_c_07', 'l_02_c_08', 'l_02_c_09', 'l_02_c_10',\n",
        "                          'l_03_c_01', 'l_03_c_02', 'l_03_c_03', 'l_03_c_04', 'l_03_c_05',\n",
        "                          'l_03_c_06', 'l_03_c_07', 'l_03_c_08', 'l_03_c_09', 'l_03_c_10',\n",
        "                          'l_04_c_01', 'l_04_c_02', 'l_04_c_03', 'l_04_c_04', 'l_04_c_05',\n",
        "                          'l_04_c_06', 'l_04_c_07', 'l_04_c_08', 'l_04_c_09', 'l_04_c_10',\n",
        "                          'l_05_c_01', 'l_05_c_02', 'l_05_c_03', 'l_05_c_04', 'l_05_c_05',\n",
        "                          'l_05_c_06', 'l_05_c_07', 'l_05_c_08', 'l_05_c_09', 'l_05_c_10',\n",
        "                          'l_06_c_01', 'l_06_c_02', 'l_06_c_03', 'l_06_c_04', 'l_06_c_05',\n",
        "                          'l_06_c_06', 'l_06_c_07', 'l_06_c_08', 'l_06_c_09', 'l_06_c_10',\n",
        "                          'l_07_c_01', 'l_07_c_02', 'l_07_c_03', 'l_07_c_04', 'l_07_c_05',\n",
        "                          'l_07_c_06', 'l_07_c_07', 'l_07_c_08', 'l_07_c_09', 'l_07_c_10',\n",
        "                          'l_08_c_01', 'l_08_c_02', 'l_08_c_03', 'l_08_c_04', 'l_08_c_05',\n",
        "                          'l_08_c_06', 'l_08_c_07', 'l_08_c_08', 'l_08_c_09', 'l_08_c_10',\n",
        "                          'l_09_c_01', 'l_09_c_02', 'l_09_c_03', 'l_09_c_04', 'l_09_c_05',\n",
        "                          'l_09_c_06', 'l_09_c_07', 'l_09_c_08', 'l_09_c_09', 'l_09_c_10',\n",
        "                          'l_10_c_01', 'l_10_c_02', 'l_10_c_03', 'l_10_c_04', 'l_10_c_05',\n",
        "                          'l_10_c_06', 'l_10_c_07', 'l_10_c_08', 'l_10_c_09', 'l_10_c_10',\n",
        "                        ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFNIYv2XAiQa",
        "outputId": "562704f7-8789-465e-c5dc-f5e0963e8f09"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_demention = 5\n",
        "hidden_layers_count = 2"
      ],
      "metadata": {
        "id": "-ZcLlpFd-btl"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment():\n",
        "\n",
        "    for seed in range(1):\n",
        "\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        X_train = []\n",
        "        X_test = []\n",
        "        y_train = []\n",
        "        y_test = []\n",
        "\n",
        "        for i in range(len(X_draft)):\n",
        "            if train_indexes_mask[i] == 1:\n",
        "                X_train.append(X_draft[i])\n",
        "                y_train.append(y_draft[i])\n",
        "            else:\n",
        "                X_test.append(X_draft[i])\n",
        "                y_test.append(y_draft[i])\n",
        "\n",
        "        X_train = torch.tensor(X_train, dtype=torch.float32, requires_grad=True)\n",
        "        X_test = torch.tensor(X_test, dtype=torch.float32, requires_grad=True)\n",
        "        y_train = torch.tensor(y_train, dtype=torch.float32, requires_grad=True)\n",
        "        y_test = torch.tensor(y_test, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        model = NN(2, hidden_layers_count, hidden_demention, 1)\n",
        "\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00005)\n",
        "\n",
        "        epoch, loss, acc, test_loss, test_acc = train_nn(model, optimizer, loss_fn, X_train, y_train, X_test, y_test, noe=25000)\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch}, loss: {loss: .5f}, acc: {acc: .5f}%, test loss: {test_loss: .5f}, test acc: {test_acc: .5f}%')\n",
        "\n",
        "        # записывать в файл следует список (list) хранящий данные в следующем порядке:\n",
        "        #   1. seed - параметр, который установлен в функции torch.manual_seed(seed);\n",
        "        #   2. количество скрытых нейронных слоев\n",
        "        #   3. количество нейроннов в каждом скрытом слое\n",
        "        #   4. количество эпох (итераций обучения)\n",
        "        #   5. вид функции loss\n",
        "        #   6. метод оптимизации\n",
        "        #   7. learning rate\n",
        "        #   8. weight decay\n",
        "        #   9. loss на тренировочных данных\n",
        "        #  10. accuracy на тренировочных данных\n",
        "        #  11. loss на тестовых данных\n",
        "        #  12. accuracy на тестовых данных\n",
        "        #  13 - 112. маска тренировочных данных. 1, если позиция используется для обучения, 0, если используется для теста.\n",
        "        expres_storage_data = []\n",
        "        expres_storage_data = [seed, hidden_layers_count, hidden_demention, epoch, 'MSELoss', 'Adam', 0.001, 0.00005, loss, acc, test_loss, test_acc]\n",
        "        expres_storage_data.extend(train_indexes_mask)\n",
        "        expres_storage.dataadd(expres_storage_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "aStR7K25IEDR"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvlu4P6lLuwH",
        "outputId": "b92eb7c0-800d-4b13-9b78-cf4e87c4b161"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Total: 100%|#############################| 30000/30000 [00:46<00:00, 644.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed: 0, Epoch: 30000, loss:  0.00000, acc:  89.47369%, test loss:  0.02478, test acc:  0.00000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# str_line = f'    '\n",
        "# for i in range(10):\n",
        "#     str_line = str_line + f'{i+1:7}'\n",
        "# print(str_line)\n",
        "# print()\n",
        "\n",
        "# for i in range(10):\n",
        "#     str_line = f'{i+1:2}  '\n",
        "#     for j in range(10):\n",
        "#         x = torch.tensor([i+1, j+1], dtype=torch.float32)\n",
        "#         y = model(x)\n",
        "#         err = (i+1)*(j+1) - torch.round(y*100).data[0]\n",
        "#         str_line = str_line + f'{err:7}'\n",
        "#     print(str_line)\n"
      ],
      "metadata": {
        "id": "heHEY5mKniqg"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}